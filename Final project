Linear Regression
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Load the data
data = pd.read_csv('goodreads_train.csv')

# Split the data into input (X) and output (y) variables
X = data[['review_text']]
y = data['rating']

# Use CountVectorizer to transform the text data into numerical features
vectorizer = CountVectorizer(stop_words='english')
X_text = vectorizer.fit_transform(X['review_text'])

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42)

# Create a linear regression object
reg = LinearRegression()

# Train the model using the training data
reg.fit(X_train, y_train)

# Make predictions on the testing data
y_pred = reg.predict(X_test)

# Print the model performance metrics
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
print("Coefficient of determination (R^2): %.2f" % r2_score(y_test, y_pred))


## Load the libraries
import os
import numpy as np 
import pandas as pd 

# data viz
import matplotlib.pyplot as plt 
import seaborn as sns

# machine learning
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import mean_absolute_error as mae
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline


## Load the libraries
import os
import numpy as np 
import pandas as pd 

# data viz
import matplotlib.pyplot as plt 
import seaborn as sns

# machine learning
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import mean_absolute_error as mae
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline

## Load the libraries
import os
import numpy as np 
import pandas as pd 

# data viz
import matplotlib.pyplot as plt 
import seaborn as sns

# machine learning
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import mean_absolute_error as mae
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline

Multinomial Naive Bayes 

## Load the libraries
import os
import numpy as np 
import pandas as pd 

# data viz
import matplotlib.pyplot as plt 
import seaborn as sns

# machine learning
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import mean_absolute_error as mae
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline


import warnings
warnings.filterwarnings("ignore")

%matplotlib inline

## Load the dataset into a pandas data frame
goodreadstrain_df = pd.read_csv(os.path.abspath('goodreads_train.csv'))
goodreadstest_df = pd.read_csv(os.path.abspath('goodreads_test.csv'))


Exploratory Analysis
In [49]:
goodreadstrain_df.shape


goodreadstrain_df.head()

goodreadstest_df.shape

goodreadstest_df.head()

goodreadstrain_df.info()

## Checking for missing value

goodreadstrain_df.isnull().sum()

goodreadstrain_df['rating'].value_counts()

sns.countplot(x= 'rating', data = goodreadstrain_df, palette = 'hls')
plt.title('Rating distribution in the training set', fontweight="bold")
plt.xlabel('Rating')
plt.ylabel('Number of reviews')


# Considering only variables of interest
X = goodreadstrain_df['review_text']

y = goodreadstrain_df['rating'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=42)

# build a pipeline
model_tfidf = make_pipeline(TfidfVectorizer(), MultinomialNB())

# training the model
model_tfidf.fit(X_train, y_train)

# predicting the model on test
pred_labels = model_tfidf.predict(X_test)

# accuracy of the model
accuracy = accuracy_score(y_test, pred_labels)
print(f'Accuracy of the naive bayes model is : {accuracy:.4f}')

print(confusion_matrix(y_test, pred_labels))

print(classification_report(y_test, pred_labels))

# calculate MAE
MAE = mae(y_test, pred_labels)
print("Mean absolute error : " + str(MAE))

Random Forest Model

import numpy as np # data manipulation
import pandas as pd # dataframe library

import matplotlib.pyplot as plt # data visualization
import seaborn as sns # make plots prettier

from sklearn.model_selection import train_test_split

# models
from sklearn.ensemble import RandomForestClassifier

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# prints all plots in the console without writing .show()
%matplotlib inline

# ignore all warnings
import warnings
warnings.filterwarnings('ignore')

Read and split train test data:
In [3]:
# Read GoodReads reviews csv file
df = pd.read_csv('goodreads_train.csv')

# Save predictor variable as X
X = df['review_text']

# Save dependent variable as y
y = pd.to_numeric(df['rating'])

# Split 70% of the dataset for training and 30% for testing
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 100)

Create and fit model:
In [13]:
# Create a pipeline with following steps:
# 1. Transform raw text into tokens using TfidfVectorizer
# 2. Create Random Forest Classifier model
rf_classifier_pipeline = make_pipeline(
    TfidRandom Forest Model
Read and split train test data:
# Read GoodReads reviews csv file
df = pd.read_csv('goodreads_train.csv')
•
# Save predictor variable as X
X = df['review_text']
•
# Save dependent variable as y
y = pd.to_numeric(df['rating'])
•
# Split 70% of the dataset for training and 30% for testing
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 100)
fVectorizer(), 
    RandomForestClassifier(
        max_depth = 50, 
        max_features = 1000, 
        n_estimators = 50, 
        random_state = 100
    )
)

# Fit the model with training dataset
rf_classifier_pipeline.fit(X_train, y_train)

# Calcuate the accuracy score
rf_classifier_pipeline.score(X_test, y_test) # 0.4456407407407407

Classification Report:
In [15]:
label = rf_classifier_pipeline.predict(X_test)
print(classification_report(y_test, label))






